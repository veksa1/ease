{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253c201",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c67dbbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/migraine_features_augmented.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load augmented features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/migraine_features_augmented.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load normalizer\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/migraine_features_augmented.csv'"
     ]
    }
   ],
   "source": [
    "# Load augmented features\n",
    "df_features = pd.read_csv('../data/migraine_features_augmented.csv')\n",
    "print(f\"Loaded {len(df_features)} features\")\n",
    "\n",
    "# Load normalizer\n",
    "with open('../data/feature_normalizer.pkl', 'rb') as f:\n",
    "    normalizer = pickle.load(f)\n",
    "\n",
    "print(f\"\\nNormalizer contains:\")\n",
    "for key in normalizer.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce9b3c",
   "metadata": {},
   "source": [
    "## 2. Visualize Impact Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot impact patterns for each category\n",
    "categories = df_features['category'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get features in this category\n",
    "    cat_features = df_features[df_features['category'] == category]\n",
    "    \n",
    "    for _, row in cat_features.iterrows():\n",
    "        pattern = [int(x) for x in row['Migraine Impact Pattern'].split(',')]\n",
    "        bin_centers = json.loads(row['bin_centers'])\n",
    "        \n",
    "        ax.plot(bin_centers, pattern, marker='o', label=row['variable'], alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f'{category} - Impact Patterns', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Feature Value')\n",
    "    ax.set_ylabel('Migraine Risk Score')\n",
    "    ax.legend(fontsize=8, loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/impact_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved impact patterns visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6821f",
   "metadata": {},
   "source": [
    "## 3. Prior Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prior distributions\n",
    "priors = normalizer['priors']\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (var_name, prior_info) in enumerate(priors.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    dist = prior_info.get('dist', 'normal')\n",
    "    \n",
    "    if dist == 'normal':\n",
    "        mu = prior_info['mu']\n",
    "        sigma = prior_info['sigma']\n",
    "        x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "        y = (1/(sigma * np.sqrt(2*np.pi))) * np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "        ax.plot(x, y, 'b-', linewidth=2)\n",
    "        ax.axvline(mu, color='r', linestyle='--', alpha=0.5, label=f'μ={mu}')\n",
    "        \n",
    "    elif dist == 'lognormal':\n",
    "        mu_ln = prior_info['mu_ln']\n",
    "        sigma_ln = prior_info['sigma_ln']\n",
    "        x = np.linspace(0.1, np.exp(mu_ln + 3*sigma_ln), 100)\n",
    "        y = (1/(x * sigma_ln * np.sqrt(2*np.pi))) * np.exp(-0.5*((np.log(x)-mu_ln)/sigma_ln)**2)\n",
    "        ax.plot(x, y, 'g-', linewidth=2)\n",
    "        ax.axvline(np.exp(mu_ln), color='r', linestyle='--', alpha=0.5, label=f'median={np.exp(mu_ln):.1f}')\n",
    "        \n",
    "    elif dist == 'uniform':\n",
    "        min_val = prior_info['min']\n",
    "        max_val = prior_info['max']\n",
    "        x = np.array([min_val, min_val, max_val, max_val])\n",
    "        y = np.array([0, 1/(max_val-min_val), 1/(max_val-min_val), 0])\n",
    "        ax.plot(x, y, 'm-', linewidth=2)\n",
    "    \n",
    "    ax.set_title(var_name, fontsize=9)\n",
    "    ax.set_xlabel('Value', fontsize=8)\n",
    "    ax.set_ylabel('Density', fontsize=8)\n",
    "    ax.tick_params(labelsize=7)\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/prior_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved prior distributions visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05157dc1",
   "metadata": {},
   "source": [
    "## 4. Risk Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699efc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk weight matrix W_feat_to_Z\n",
    "W = normalizer['W_feat_to_Z']\n",
    "features = normalizer['features']\n",
    "\n",
    "latent_names = ['Stress', 'Sleep', 'Environment', 'Hormonal', 'Lifestyle']\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(W, \n",
    "            xticklabels=features, \n",
    "            yticklabels=latent_names,\n",
    "            cmap='YlOrRd', \n",
    "            annot=False, \n",
    "            fmt='.2f',\n",
    "            cbar_kws={'label': 'Weight'})\n",
    "\n",
    "plt.title('Feature-to-Latent Weight Matrix (W_feat_to_Z)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Latent Dimensions', fontsize=12)\n",
    "plt.xticks(rotation=90, ha='right', fontsize=9)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/weight_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved weight matrix visualization\")\n",
    "print(f\"\\nMatrix shape: {W.shape}\")\n",
    "print(f\"Non-zero weights per latent dimension: {(W > 0).sum(axis=1).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4856460",
   "metadata": {},
   "source": [
    "## 5. Test Normalizer on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scorer and normalizer on sample values\n",
    "scorers = normalizer['scorers']\n",
    "normalizers = normalizer['normalizers']\n",
    "\n",
    "print(\"Testing normalizer on sample values:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test a few features with their mean, low, and high values\n",
    "test_features = [\n",
    "    'Sleep Duration (hours)',\n",
    "    'Stress Level (1-10)',\n",
    "    'Caffeine Intake (mg)',\n",
    "    'Exercise Duration (min)',\n",
    "]\n",
    "\n",
    "for var_name in test_features:\n",
    "    row = df_features[df_features['variable'] == var_name].iloc[0]\n",
    "    \n",
    "    min_val = row['min']\n",
    "    mean_val = row['mean']\n",
    "    max_val = row['max']\n",
    "    \n",
    "    scorer = scorers[var_name]\n",
    "    normalizer_fn = normalizers[var_name]\n",
    "    \n",
    "    print(f\"\\n{var_name}:\")\n",
    "    print(f\"  Range: [{min_val}, {max_val}]\")\n",
    "    \n",
    "    for label, val in [('Min', min_val), ('Mean', mean_val), ('Max', max_val)]:\n",
    "        score = scorer(val)\n",
    "        norm = normalizer_fn(val)\n",
    "        print(f\"  {label:6s} = {val:6.1f}  →  Risk Score: {score:2d}/10  |  Normalized: {norm:+6.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7656e1",
   "metadata": {},
   "source": [
    "## 6. Category-wise Weight Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417798a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature weights by category\n",
    "category_weights = df_features.groupby('category')['Weight'].agg(['mean', 'sum', 'count'])\n",
    "category_weights = category_weights.sort_values('sum', ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of total weights\n",
    "category_weights['sum'].plot(kind='bar', ax=axes[0], color='steelblue', alpha=0.7)\n",
    "axes[0].set_title('Total Weight by Category', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Category')\n",
    "axes[0].set_ylabel('Total Weight')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pie chart of feature count\n",
    "category_counts = df_features['category'].value_counts()\n",
    "axes[1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Feature Distribution by Category', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/category_weights.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCategory Summary:\")\n",
    "print(category_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11282f56",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook validates the feature normalization system created in Ticket 003:\n",
    "\n",
    "✅ **Impact Patterns**: Visualized risk scores across feature ranges\n",
    "\n",
    "✅ **Prior Distributions**: Showed population-level distributions for all features\n",
    "\n",
    "✅ **Weight Matrix**: Mapped features to latent dimensions\n",
    "\n",
    "✅ **Normalizer Testing**: Validated scoring and normalization functions\n",
    "\n",
    "**Next Steps**:\n",
    "- Use `feature_normalizer.pkl` in Ticket 004 (Simulator)\n",
    "- Integrate with ALINE pretraining pipeline\n",
    "- Apply to real-world data collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aline (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
